{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:08:12.883257Z",
     "start_time": "2020-06-23T10:08:10.912056Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:08:12.887223Z",
     "start_time": "2020-06-23T10:08:12.885039Z"
    }
   },
   "outputs": [],
   "source": [
    "# MNIST dataset parameters.\n",
    "num_classes = 10 # total classes (0-9 digits).\n",
    "epochs = 3\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:08:13.339557Z",
     "start_time": "2020-06-23T10:08:12.889823Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare MNIST data.\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Convert to float32.\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "# Normalize images value from [0, 255] to [0, 1].\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "\n",
    "# Use tf.data API to shuffle and batch data.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat(epochs).shuffle(5000).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:08:13.354252Z",
     "start_time": "2020-06-23T10:08:13.341401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training parameters.\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Network parameters.\n",
    "n_hidden_1 = 128  # 1st layer number of neurons.\n",
    "n_hidden_2 = 256  # 2nd layer number of neurons.\n",
    "\n",
    "\n",
    "# Create TF Model.\n",
    "class DenseNet(tf.keras.Model):\n",
    "    # Set layers.\n",
    "    def __init__(self):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten(input_shape=(28, 28))\n",
    "        # First fully-connected hidden layer.\n",
    "        self.fc1 = tf.keras.layers.Dense(n_hidden_1, activation=tf.nn.relu)\n",
    "        # First fully-connected hidden layer.\n",
    "        self.fc2 = tf.keras.layers.Dense(n_hidden_2, activation=tf.nn.relu)\n",
    "        # Second fully-connecter hidden layer.\n",
    "        self.out = tf.keras.layers.Dense(num_classes)\n",
    "\n",
    "    # Set forward pass.\n",
    "    def call(self, inputs):\n",
    "        x = self.flatten(inputs)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        return tf.nn.softmax(x)\n",
    "\n",
    "\n",
    "dense_model = DenseNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:08:13.499511Z",
     "start_time": "2020-06-23T10:08:13.355572Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = 'checkpoints/dense' + datetime.now().strftime(\n",
    "    \"%Y%m%d-%H%M%S\") + '.ckpt'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                save_best_only=True,\n",
    "                                                save_weights_only=True,\n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=1)\n",
    "\n",
    "\n",
    "%load_ext tensorboard\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/dense/\n",
    "logdir=\"logs/dense/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric_acc = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:08:25.111913Z",
     "start_time": "2020-06-23T10:08:13.502063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2773/2813 [============================>.] - ETA: 0s - loss: 1.6539 - sparse_categorical_accuracy: 0.8277\n",
      "Epoch 00001: val_loss improved from inf to 1.53712, saving model to checkpoints/dense20200623-190813.ckpt\n",
      "2813/2813 [==============================] - 4s 1ms/step - loss: 1.6522 - sparse_categorical_accuracy: 0.8292 - val_loss: 1.5371 - val_sparse_categorical_accuracy: 0.9306\n",
      "Epoch 2/3\n",
      "2807/2813 [============================>.] - ETA: 0s - loss: 1.5267 - sparse_categorical_accuracy: 0.9406\n",
      "Epoch 00002: val_loss improved from 1.53712 to 1.52021, saving model to checkpoints/dense20200623-190813.ckpt\n",
      "2813/2813 [==============================] - 3s 1ms/step - loss: 1.5267 - sparse_categorical_accuracy: 0.9407 - val_loss: 1.5202 - val_sparse_categorical_accuracy: 0.9459\n",
      "Epoch 3/3\n",
      "2809/2813 [============================>.] - ETA: 0s - loss: 1.5111 - sparse_categorical_accuracy: 0.9547\n",
      "Epoch 00003: val_loss improved from 1.52021 to 1.50924, saving model to checkpoints/dense20200623-190813.ckpt\n",
      "2813/2813 [==============================] - 4s 1ms/step - loss: 1.5111 - sparse_categorical_accuracy: 0.9547 - val_loss: 1.5092 - val_sparse_categorical_accuracy: 0.9556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc0183aaf10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_model.compile(optimizer, loss, metrics=[metric_acc])\n",
    "dense_model.fit(\n",
    "    train_data,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint, tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:08:25.127477Z",
     "start_time": "2020-06-23T10:08:25.124445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  33024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  2570      \n",
      "=================================================================\n",
      "Total params: 136,074\n",
      "Trainable params: 136,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:08:25.434613Z",
     "start_time": "2020-06-23T10:08:25.130056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 783us/step - loss: 1.5092 - sparse_categorical_accuracy: 0.9556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5092374086380005, 0.9556000232696533]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_model.load_weights(checkpoint_path)\n",
    "dense_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:08:25.453569Z",
     "start_time": "2020-06-23T10:08:25.436265Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training parameters.\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Network parameters.\n",
    "conv1_filters = 32  # number of filters for 1st conv layer.\n",
    "conv2_filters = 64  # number of filters for 2nd conv layer.\n",
    "fc1_units = 1024  # number of neurons for 1st fully-connected layer.\n",
    "\n",
    "\n",
    "# Create TF Model.\n",
    "class ConvNet(tf.keras.Model):\n",
    "    # Set layers.\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5.\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32,\n",
    "                                            kernel_size=5,\n",
    "                                            activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with kernel size of 2 and strides of 2.\n",
    "        self.maxpool1 = tf.keras.layers.MaxPool2D(2, strides=2)\n",
    "\n",
    "        # Convolution Layer with 64 filters and a kernel size of 3.\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64,\n",
    "                                            kernel_size=3,\n",
    "                                            activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with kernel size of 2 and strides of 2.\n",
    "        self.maxpool2 = tf.keras.layers.MaxPool2D(2, strides=2)\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer.\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "        # Fully connected layer.\n",
    "        self.fc1 = tf.keras.layers.Dense(1024)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied).\n",
    "        self.dropout = tf.keras.layers.Dropout(rate=0.5)\n",
    "\n",
    "        # Output layer, class prediction.\n",
    "        self.out = tf.keras.layers.Dense(num_classes)\n",
    "\n",
    "    # Set forward pass.\n",
    "    def call(self, inputs):\n",
    "        x = tf.reshape(inputs, [-1, 28, 28, 1])\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "        return tf.nn.softmax(x)\n",
    "\n",
    "\n",
    "conv_model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:08:25.596734Z",
     "start_time": "2020-06-23T10:08:25.455328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'checkpoints/conv' + datetime.now().strftime(\n",
    "    \"%Y%m%d-%H%M%S\") + '.ckpt'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                save_best_only=True,\n",
    "                                                save_weights_only=True,\n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=1)\n",
    "\n",
    "\n",
    "%load_ext tensorboard\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/conv/\n",
    "logdir=\"logs/conv/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric_acc = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:13:01.519712Z",
     "start_time": "2020-06-23T10:08:25.599098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2813/2813 [==============================] - ETA: 0s - loss: 1.5012 - sparse_categorical_accuracy: 0.9606\n",
      "Epoch 00001: val_loss improved from inf to 1.47929, saving model to checkpoints/conv20200623-190825.ckpt\n",
      "2813/2813 [==============================] - 86s 30ms/step - loss: 1.5012 - sparse_categorical_accuracy: 0.9606 - val_loss: 1.4793 - val_sparse_categorical_accuracy: 0.9817\n",
      "Epoch 2/3\n",
      "2812/2813 [============================>.] - ETA: 0s - loss: 1.4819 - sparse_categorical_accuracy: 0.9791\n",
      "Epoch 00002: val_loss did not improve from 1.47929\n",
      "2813/2813 [==============================] - 103s 37ms/step - loss: 1.4819 - sparse_categorical_accuracy: 0.9791 - val_loss: 1.4823 - val_sparse_categorical_accuracy: 0.9787\n",
      "Epoch 3/3\n",
      "2813/2813 [==============================] - ETA: 0s - loss: 1.4814 - sparse_categorical_accuracy: 0.9797\n",
      "Epoch 00003: val_loss did not improve from 1.47929\n",
      "2813/2813 [==============================] - 86s 31ms/step - loss: 1.4814 - sparse_categorical_accuracy: 0.9797 - val_loss: 1.4798 - val_sparse_categorical_accuracy: 0.9814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fbff8bae4d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.compile(optimizer, loss, metrics=[metric_acc])\n",
    "conv_model.fit(\n",
    "    train_data,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint, tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:13:01.536174Z",
     "start_time": "2020-06-23T10:13:01.532141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  1639424   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  10250     \n",
      "=================================================================\n",
      "Total params: 1,669,002\n",
      "Trainable params: 1,669,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:13:03.705955Z",
     "start_time": "2020-06-23T10:13:01.538195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 1.4793 - sparse_categorical_accuracy: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4792938232421875, 0.9817000031471252]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.load_weights(checkpoint_path)\n",
    "conv_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:13:03.724604Z",
     "start_time": "2020-06-23T10:13:03.707631Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# Network Parameters\n",
    "# MNIST image shape is 28*28px, we will then handle 28 sequences of 28 timesteps for every sample.\n",
    "num_input = 28  # number of sequences.\n",
    "timesteps = 28  # timesteps.\n",
    "num_units = 32  # number of neurons for the LSTM layer.\n",
    "\n",
    "\n",
    "# Create LSTM Model.\n",
    "class LSTM(tf.keras.Model):\n",
    "    # Set layers.\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.reshape = tf.keras.layers.Lambda(lambda x: tf.reshape(x, [-1, 28, 28]))\n",
    "        # RNN (LSTM) hidden layer.\n",
    "        self.lstm_layer = tf.keras.layers.LSTM(units=num_units)\n",
    "        self.out = tf.keras.layers.Dense(num_classes)\n",
    "\n",
    "    # Set forward pass.\n",
    "    def call(self, inputs):\n",
    "        # LSTM layer.\n",
    "        x = self.reshape(inputs)\n",
    "        x = self.lstm_layer(x)\n",
    "        # Output layer (num_classes).\n",
    "        x = self.out(x)\n",
    "        return tf.nn.softmax(x)\n",
    "\n",
    "lstm_model = LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:13:03.872619Z",
     "start_time": "2020-06-23T10:13:03.726467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'checkpoints/lstm' + datetime.now().strftime(\n",
    "    \"%Y%m%d-%H%M%S\") + '.ckpt'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                save_best_only=True,\n",
    "                                                save_weights_only=True,\n",
    "                                                monitor='val_loss',\n",
    "                                                verbose=1)\n",
    "\n",
    "\n",
    "%load_ext tensorboard\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/lstm/\n",
    "logdir=\"logs/lstm/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric_acc = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:14:32.075362Z",
     "start_time": "2020-06-23T10:13:03.874608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2810/2813 [============================>.] - ETA: 0s - loss: 1.6393 - sparse_categorical_accuracy: 0.8377\n",
      "Epoch 00001: val_loss improved from inf to 1.53038, saving model to checkpoints/lstm20200623-191303.ckpt\n",
      "2813/2813 [==============================] - 29s 10ms/step - loss: 1.6393 - sparse_categorical_accuracy: 0.8377 - val_loss: 1.5304 - val_sparse_categorical_accuracy: 0.9352\n",
      "Epoch 2/3\n",
      "2810/2813 [============================>.] - ETA: 0s - loss: 1.5207 - sparse_categorical_accuracy: 0.9437\n",
      "Epoch 00002: val_loss improved from 1.53038 to 1.51104, saving model to checkpoints/lstm20200623-191303.ckpt\n",
      "2813/2813 [==============================] - 29s 10ms/step - loss: 1.5207 - sparse_categorical_accuracy: 0.9436 - val_loss: 1.5110 - val_sparse_categorical_accuracy: 0.9517\n",
      "Epoch 3/3\n",
      "2812/2813 [============================>.] - ETA: 0s - loss: 1.5044 - sparse_categorical_accuracy: 0.9586\n",
      "Epoch 00003: val_loss improved from 1.51104 to 1.50151, saving model to checkpoints/lstm20200623-191303.ckpt\n",
      "2813/2813 [==============================] - 29s 10ms/step - loss: 1.5044 - sparse_categorical_accuracy: 0.9586 - val_loss: 1.5015 - val_sparse_categorical_accuracy: 0.9603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc009079a10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.compile(optimizer, loss, metrics=[metric_acc])\n",
    "lstm_model.fit(\n",
    "    train_data,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=epochs,\n",
    "    callbacks=[checkpoint, tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:14:32.090889Z",
     "start_time": "2020-06-23T10:14:32.086405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda (Lambda)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  7808      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  330       \n",
      "=================================================================\n",
      "Total params: 8,138\n",
      "Trainable params: 8,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:14:32.897447Z",
     "start_time": "2020-06-23T10:14:32.093001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5015 - sparse_categorical_accuracy: 0.9603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5015079975128174, 0.9603000283241272]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.load_weights(checkpoint_path)\n",
    "lstm_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T10:14:32.905271Z",
     "start_time": "2020-06-23T10:14:32.898785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 61684), started 1:54:52 ago. (Use '!kill 61684' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c73db166cbc617cc\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c73db166cbc617cc\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6008;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
